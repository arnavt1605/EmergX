{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14401625,"sourceType":"datasetVersion","datasetId":9197878}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Model used: nli-deberta-v3-base","metadata":{}},{"cell_type":"code","source":"!pip install protobuf==3.20.3 -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-07T04:55:12.675944Z","iopub.execute_input":"2026-01-07T04:55:12.676592Z","iopub.status.idle":"2026-01-07T04:55:17.463149Z","shell.execute_reply.started":"2026-01-07T04:55:12.676537Z","shell.execute_reply":"2026-01-07T04:55:17.462241Z"}},"outputs":[{"name":"stdout","text":"The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngrain 0.2.15 requires protobuf>=5.28.3, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.20.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nray 2.52.1 requires click!=8.3.*,>=7.0, but you have click 8.3.1 which is incompatible.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\nbigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"reference_answers = {\n\n    \"Q1\": (\n        \"Object-Oriented Programming (OOP) is a programming paradigm that organizes software \"\n        \"design around objects that combine data and behavior. Unlike procedural programming, \"\n        \"which focuses on functions operating on data, OOP models real-world entities as objects. \"\n        \"The four core principles of OOP are encapsulation, abstraction, inheritance, and polymorphism. \"\n        \"Encapsulation hides internal data and exposes it through controlled interfaces, abstraction \"\n        \"focuses on essential features, inheritance enables code reuse through class hierarchies, and \"\n        \"polymorphism allows different objects to respond differently to the same method. A real-world \"\n        \"example of encapsulation is a bank account, where balance details are accessed only through \"\n        \"methods like deposit and withdraw. OOP may not be ideal for small or performance-critical \"\n        \"systems such as embedded software.\"\n    ),\n\n    \"Q2\": (\n        \"Arrays and linked lists are fundamental data structures used to store collections of elements. \"\n        \"Arrays store elements in contiguous memory locations, allowing constant-time access using an \"\n        \"index, but insertions and deletions are costly because elements may need to be shifted. Linked \"\n        \"lists store elements in non-contiguous memory locations, where each node contains data and a \"\n        \"reference to the next node, making access slower due to traversal but allowing efficient \"\n        \"insertions and deletions. Arrays provide O(1) access and O(n) insertion and deletion in the \"\n        \"worst case, while linked lists provide O(n) access and O(1) insertion or deletion when the \"\n        \"position is known. A real-world example where linked lists are useful is a music playlist.\"\n    ),\n\n    \"Q3\": (\n        \"Time complexity measures how an algorithm’s running time grows as the input size increases, \"\n        \"and it is important for comparing algorithms independently of hardware. Big-O notation \"\n        \"expresses the upper bound of an algorithm’s growth rate. Linear time O(n) occurs when an \"\n        \"algorithm processes each element once, logarithmic time O(log n) appears in algorithms like \"\n        \"binary search, and quadratic time O(n^2) occurs in algorithms with nested loops such as \"\n        \"bubble sort. Worst-case analysis is preferred because it guarantees performance limits under \"\n        \"all possible input conditions.\"\n    ),\n\n    \"Q4\": (\n        \"Compiled programming languages translate source code into machine code before execution, \"\n        \"producing an executable file, while interpreted languages execute code line by line at runtime \"\n        \"using an interpreter. Examples of compiled languages include C and C++, while Python and \"\n        \"JavaScript are commonly interpreted. Just-In-Time compilation, used in languages like Java, \"\n        \"combines both approaches by compiling frequently executed code segments at runtime to improve \"\n        \"performance. Interpreted languages are not always slower than compiled ones due to modern \"\n        \"runtime optimizations.\"\n    ),\n\n    \"Q5\": (\n        \"A process is an independent program in execution with its own memory space, while a thread \"\n        \"is a lightweight unit of execution within a process that shares memory with other threads. \"\n        \"Context switching is the mechanism by which the operating system saves the state of a running \"\n        \"task and restores another, allowing multitasking and efficient CPU utilization. Processes do \"\n        \"not share memory by default, making them safer but heavier, whereas threads share memory, \"\n        \"enabling faster communication but requiring synchronization. Multithreading improves \"\n        \"performance in applications such as web servers handling multiple client requests.\"\n    ),\n\n    \"Q6\": (\n        \"Database normalization is the process of organizing data to reduce redundancy and improve \"\n        \"integrity. First normal form ensures atomic values with no repeating groups. Second normal \"\n        \"form removes partial dependencies so that non-key attributes depend on the entire primary key. \"\n        \"Third normal form removes transitive dependencies so that non-key attributes depend only on \"\n        \"the primary key. Excessive normalization can lead to complex queries and performance overhead \"\n        \"due to multiple joins. Denormalization is often used in read-heavy systems such as analytics \"\n        \"and reporting platforms.\"\n    ),\n\n    \"Q7\": (\n        \"Machine Learning enables systems to learn patterns from data rather than relying on manually \"\n        \"written rules. Supervised learning uses labeled data such as spam email classification, \"\n        \"unsupervised learning works with unlabeled data for tasks like customer segmentation, and \"\n        \"reinforcement learning learns through rewards and penalties such as training agents to play \"\n        \"games. Key challenges include data dependency, bias, lack of interpretability, and difficulty \"\n        \"in generalizing to unseen data.\"\n    ),\n\n    \"Q8\": (\n        \"Artificial Intelligence is the field of creating systems capable of performing tasks that \"\n        \"require human-like intelligence, such as reasoning and decision-making. Machine Learning is a \"\n        \"subset of AI that allows systems to learn from data. Not all AI systems use Machine Learning; \"\n        \"some rely on rule-based logic. Deep learning is a subset of Machine Learning that uses multi-\"\n        \"layer neural networks. An example of non-ML AI is a rule-based expert system that uses \"\n        \"predefined rules to make decisions.\"\n    ),\n\n    \"Q9\": (\n        \"When a user enters a URL, the browser resolves the domain name to an IP address using DNS. It \"\n        \"then establishes a connection with the server using TCP through a three-way handshake. If \"\n        \"HTTPS is used, a TLS handshake encrypts the communication. The browser sends a request, the \"\n        \"server responds with encrypted data, and the browser decrypts and renders the webpage. HTTPS \"\n        \"ensures secure communication.\"\n    ),\n\n    \"Q10\": (\n        \"The Software Development Lifecycle is a structured process that includes requirement analysis, \"\n        \"design, implementation, testing, deployment, and maintenance. The waterfall model follows \"\n        \"these phases sequentially and is suitable when requirements are stable. Agile development is \"\n        \"iterative and incremental, emphasizing flexibility, continuous feedback, and frequent \"\n        \"releases. Agile is preferred for dynamic projects, while waterfall suits regulated or \"\n        \"contract-based environments.\"\n    )\n\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T04:55:17.464792Z","iopub.execute_input":"2026-01-07T04:55:17.465036Z","iopub.status.idle":"2026-01-07T04:55:17.471860Z","shell.execute_reply.started":"2026-01-07T04:55:17.465008Z","shell.execute_reply":"2026-01-07T04:55:17.471169Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T04:55:27.756926Z","iopub.execute_input":"2026-01-07T04:55:27.757580Z","iopub.status.idle":"2026-01-07T04:55:38.710875Z","shell.execute_reply.started":"2026-01-07T04:55:27.757540Z","shell.execute_reply":"2026-01-07T04:55:38.710264Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df= pd.read_csv(\"/kaggle/input/scores/scores.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T15:36:22.021492Z","iopub.execute_input":"2026-01-05T15:36:22.022426Z","iopub.status.idle":"2026-01-05T15:36:22.054515Z","shell.execute_reply.started":"2026-01-05T15:36:22.022396Z","shell.execute_reply":"2026-01-05T15:36:22.053785Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"model_name= \"cross-encoder/nli-deberta-v3-base\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSequenceClassification.from_pretrained(model_name)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T15:36:23.830279Z","iopub.execute_input":"2026-01-05T15:36:23.830614Z","iopub.status.idle":"2026-01-05T15:36:44.518145Z","shell.execute_reply.started":"2026-01-05T15:36:23.830584Z","shell.execute_reply":"2026-01-05T15:36:44.517342Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545895e7567b42079559beead03d513d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d207375a497f4c6c9db417bcd783a2c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7c24ce701ae45f0b707278974a1e5ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f11306398793455dabb009a4ddce894a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"620c86f0ccdf4de9aaf7901e35b581ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"311f32210c8a4663915b0e09e8161e87"}},"metadata":{}},{"name":"stderr","text":"2026-01-05 15:36:28.001957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767627388.204386      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767627388.258800      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767627388.749436      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767627388.749472      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767627388.749475      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767627388.749477      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e719dab794ab4334911aa33313bdf938"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T15:38:53.155943Z","iopub.execute_input":"2026-01-05T15:38:53.156678Z","iopub.status.idle":"2026-01-05T15:38:53.548036Z","shell.execute_reply.started":"2026-01-05T15:38:53.156645Z","shell.execute_reply":"2026-01-05T15:38:53.547433Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"DebertaV2ForSequenceClassification(\n  (deberta): DebertaV2Model(\n    (embeddings): DebertaV2Embeddings(\n      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): DebertaV2Encoder(\n      (layer): ModuleList(\n        (0-11): 12 x DebertaV2Layer(\n          (attention): DebertaV2Attention(\n            (self): DisentangledSelfAttention(\n              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n              (pos_dropout): Dropout(p=0.1, inplace=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): DebertaV2SelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): DebertaV2Intermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DebertaV2Output(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (rel_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n    )\n  )\n  (pooler): ContextPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0, inplace=False)\n  )\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"def nli_scores(premise, hypothesis):\n    inputs= tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True, padding=True, max_length=512) #output returned as pytorch tensor!!\n    inputs= {k: v.to(device) for k,v in inputs.items()}\n\n    with torch.no_grad():\n        outputs= model(**inputs) #unpacking\n\n    probs= F.softmax(outputs.logits, dim=1)[0]\n\n    return {\n        \"contradiction\": probs[0].item(),\n        \"neutral\": probs[1].item(),\n        \"entailment\": probs[2].item()\n    }\n\n# index 0 → contradiction \n# index 1 → neutral \n# index 2 → entailment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T15:47:38.927528Z","iopub.execute_input":"2026-01-05T15:47:38.928135Z","iopub.status.idle":"2026-01-05T15:47:38.933307Z","shell.execute_reply.started":"2026-01-05T15:47:38.928104Z","shell.execute_reply":"2026-01-05T15:47:38.932601Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"entailment_scores = []\ncontradiction_scores = []\n\nfor _, row in df.iterrows():\n    qid = row[\"question_id\"]\n    student_answer = row[\"answer\"]\n    reference_answer = reference_answers[qid]\n\n    if not student_answer.strip():\n        entailment_scores.append(0.0)\n        contradiction_scores.append(0.0)\n        continue\n\n    scores = nli_scores(reference_answer, student_answer)\n\n    entailment_scores.append(scores[\"entailment\"] * 100)\n    contradiction_scores.append(scores[\"contradiction\"] * 100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T15:48:50.906285Z","iopub.execute_input":"2026-01-05T15:48:50.906593Z","iopub.status.idle":"2026-01-05T15:48:54.839889Z","shell.execute_reply.started":"2026-01-05T15:48:50.906563Z","shell.execute_reply":"2026-01-05T15:48:54.839136Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df[\"nli_entailment_score\"] = entailment_scores\ndf[\"nli_contradiction_score\"] = contradiction_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T15:49:04.580969Z","iopub.execute_input":"2026-01-05T15:49:04.581267Z","iopub.status.idle":"2026-01-05T15:49:04.586643Z","shell.execute_reply.started":"2026-01-05T15:49:04.581242Z","shell.execute_reply":"2026-01-05T15:49:04.585911Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df.to_csv(\"/kaggle/working/scores.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-05T15:49:58.744309Z","iopub.execute_input":"2026-01-05T15:49:58.744850Z","iopub.status.idle":"2026-01-05T15:49:58.756658Z","shell.execute_reply.started":"2026-01-05T15:49:58.744820Z","shell.execute_reply":"2026-01-05T15:49:58.756014Z"}},"outputs":[],"execution_count":16}]}