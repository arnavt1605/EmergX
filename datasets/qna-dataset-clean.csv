question_id,question,answer,ideal_score
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.","Object-Oriented Programming (OOP) is a programming paradigm that organizes software design around objects, which combine data and behavior. Unlike procedural programming, which focuses on functions operating on data, OOP focuses on modeling real-world entities as objects. The four core principles of OOP are encapsulation, abstraction, inheritance, and polymorphism. Encapsulation ensures that an object's internal data is hidden and accessed only through well-defined interfaces. Abstraction focuses on exposing only essential features. Inheritance allows a class to derive properties and behavior from another class, and polymorphism enables different objects to respond differently to the same method call. A real-world example of encapsulation is a bank account, where balance details are hidden and accessed only through methods like deposit and withdraw. OOP may not be ideal for small, performance-critical systems such as low-level embedded software, where procedural programming can be simpler and faster.",95
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.","Object-Oriented Programming is a way of writing programs using objects that represent real-world entities. It differs from procedural programming because procedural programming relies mainly on functions, while OOP combines data and methods together. The four principles are encapsulation, abstraction, inheritance, and polymorphism. Encapsulation hides data inside classes, inheritance allows reuse of code, abstraction hides complexity, and polymorphism allows methods to behave differently. For example, a vehicle class can be inherited by car and bike classes. OOP may not be suitable for very small programs where it adds unnecessary complexity.",85
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.","Object-Oriented Programming is a programming style where programs are built using objects. Procedural programming focuses on step-by-step instructions, whereas OOP focuses on objects and classes. The main principles are encapsulation, inheritance, polymorphism, and abstraction. Encapsulation means keeping data safe inside objects. An example is a car class that has speed and fuel as attributes. OOP might not be a good choice when performance is the highest priority.",77
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.","OOP is a programming method that uses classes and objects. It is different from procedural programming because procedural programming uses functions. OOP has four principles like inheritance and encapsulation. For example, a student class can inherit from a person class. OOP may not be suitable for all applications.",63
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.",Object-Oriented Programming is about using objects in programs. Procedural programming is about writing functions. OOP principles include encapsulation and inheritance. A real-world example is a car object. Sometimes OOP is not needed for simple tasks.,56
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.",OOP is a type of programming. It uses objects. Procedural programming uses steps. OOP has principles like inheritance. An example is a class. OOP is not always good.,42
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.",Object-Oriented Programming uses objects. Procedural programming uses procedures. There are some principles in OOP. It can be used to make programs.,34
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.",OOP is programming with objects. It is different from procedural programming. It has rules. Example is car.,23
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.",OOP is a programming language concept. It has objects and classes.,13
Q1,"What is Object-Oriented Programming, and how does it differ from procedural programming? Explain the four core principles of Object-Oriented Programming in your answer. Furthermore, provide a real-world example that clearly shows encapsulation or inheritance, and finally, describe a scenario where Object-Oriented Programming may not be the best design choice.",I don't know Object-Oriented Programming.,0
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.","Arrays and linked lists are fundamental data structures used to store collections of elements. An array stores elements in contiguous memory locations, which allows constant-time access using an index, but makes insertion and deletion expensive because elements may need to be shifted. A linked list, on the other hand, stores elements in non-contiguous memory locations, where each node contains data and a reference to the next node, allowing efficient insertions and deletions but slower access since traversal is required. In terms of complexity, arrays provide O(1) access but O(n) insertion and deletion in the worst case, whereas linked lists provide O(n) access but O(1) insertion and deletion when the position is known. A real-world example where linked lists are better is a music playlist, where songs are frequently added or removed without the need for shifting all elements.",96
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.","Arrays and linked lists are data structures used to store multiple values. Arrays store data in continuous memory, which makes accessing elements fast, but inserting or deleting elements costly. Linked lists store elements in separate memory locations connected using pointers, which makes insertion and deletion easier. Array access time is O(1), while linked list access time is O(n). Insertions and deletions are O(n) in arrays but O(1) in linked lists. Linked lists are useful in situations like implementing undo operations where frequent insertions and deletions are required.",87
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.","An array is a collection of elements stored next to each other in memory, while a linked list stores elements using nodes that point to the next element. Arrays allow faster access, but linked lists allow easier insertion and deletion. In arrays, accessing elements takes constant time, but inserting elements can take linear time. In linked lists, accessing elements is slower. A linked list can be useful in applications like queues where elements are frequently added and removed.",78
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.","Arrays and linked lists are used to store data. Arrays store elements in continuous memory, while linked lists store elements using pointers. Arrays are faster to access, and linked lists are easier to modify. For example, linked lists can be used in dynamic data storage.",64
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.","Arrays store multiple values in memory, and linked lists store values using nodes. Arrays are fast for access, and linked lists are good for insertion and deletion. Linked lists are useful when data changes often.",54
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.",Arrays are data structures with elements stored together. Linked lists store elements separately. Arrays are fast. Linked lists are flexible.,42
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.",Arrays and linked lists store data. Arrays are simple. Linked lists have pointers.,33
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.",Arrays store data. Linked lists also store data. They are different.,22
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.",Arrays and linked lists are data structures.,12
Q2,"What are arrays and linked lists, and how do they differ from each other in terms of memory layout and access patterns? Compare their time and space complexities for standard operations such as insertion, deletion, and access. Also, describe a real-world situation where a linked list would be a better choice than an array.",I don't know arrays and linked lists.,0
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.","Time complexity is a measure of how an algorithm's running time grows as the size of the input increases, and it is significant because it helps compare algorithms independent of hardware or implementation details. Big-O notation is used to express time complexity by describing the upper bound of an algorithm's growth rate. For example, linear time O(n) occurs when an algorithm processes each element once, such as iterating through an array. Logarithmic time O(log n) appears in algorithms like binary search, where the input size is halved at each step. Quadratic time O(n²) is seen in nested loops, such as simple sorting algorithms like bubble sort. Worst-case analysis is usually preferred because it provides a guarantee on performance under all conditions, making systems more reliable and predictable.",94
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.","Time complexity explains how the execution time of an algorithm increases with input size and is important for choosing efficient solutions. Big-O notation represents this growth rate in a simplified form. An O(n) algorithm runs once for each input element, O(log n) algorithms reduce the problem size step by step like binary search, and O(n²) algorithms involve nested iterations. Worst-case analysis is considered because it shows the maximum time an algorithm may take, which is important for performance-critical applications.",86
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.","Time complexity measures how fast or slow an algorithm is depending on the input size. Big-O notation is used to represent time complexity. Linear time means the algorithm runs once per element, logarithmic time reduces the input size repeatedly, and quadratic time involves nested loops. Worst-case analysis is used because it shows the maximum time required by an algorithm",77
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.","Time complexity tells us how much time an algorithm takes. Big-O notation is used to describe it. O(n) means linear time, O(log n) is faster, and O(n²) is slower. Worst-case analysis helps understand the slowest performance.",65
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.",Time complexity is about algorithm speed. Big-O notation shows how fast an algorithm runs. Examples include O(n) and O(n²). Worst-case analysis is used to check performance.,54
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.",Time complexity shows how long an algorithm takes. Big-O notation explains it. Some algorithms are faster than others,45
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.",Time complexity is related to algorithms. Big-O is used to represent it.,32
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.",Time complexity tells about speed. Big-O is notation.,22
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.",Time complexity is about time.,11
Q3,"What is time complexity, and why is it significant in algorithm design? Describe Big-O notation and its role in indicating algorithm efficiency. Illustrate linear time, logarithmic time, and quadratic time complexities with simple examples and state the reasons for which worst-case analysis is usually considered when evaluating algorithms.",I don't know time complexity.,0
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.","Compiled programming languages translate the entire source code into machine code before execution, producing an executable file that can run directly on the system. Interpreted languages execute code line by line at runtime using an interpreter. For example, C and C++ are compiled languages where the compiler converts source code into an executable, while Python and JavaScript are interpreted languages that rely on an interpreter. Just-In-Time compilation, used in languages like Java, combines both approaches by compiling frequently used code segments at runtime to improve performance. Interpreted languages are not always slower than compiled ones because modern interpreters and JIT compilers apply optimizations that can significantly improve execution speed.",97
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.","Compiled languages convert source code into machine code before execution, while interpreted languages run code line by line. Examples of compiled languages include C and Go, while Python and JavaScript are interpreted. JIT compilation improves performance by compiling code during execution. Interpreted languages are not always slower because runtime optimizations and JIT can make them efficient.",85
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.","Compiled languages generate machine code before running, whereas interpreted languages execute code during runtime. C is an example of a compiled language and Python is an interpreted language. JIT compilation helps improve speed by compiling code when needed. Interpreted languages may be slower, but optimizations reduce the difference.",76
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.","Compiled languages run faster because they are converted to machine code first, while interpreted languages run line by line. Examples include C for compiled and Python for interpreted. JIT compilation improves performance. Interpreted languages are sometimes slower.",65
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.",Compiled languages are converted before execution. Interpreted languages are executed while running. Examples include C and Python. JIT helps improve speed.,53
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.",Compiled languages use a compiler. Interpreted languages use an interpreter. Some languages use JIT.,42
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.",Compiled languages are faster. Interpreted languages are slower.,31
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.",Compiled and interpreted languages are different types.,22
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.",Programming languages can be compiled or interpreted.,12
Q4,"What separates compiled programming languages from interpreted ones? Illustrate with examples how a program's source code is converted and run in both scenarios. Give a few examples of languages from both categories, indicate the position of Just-In-Time (JIT) compilation in this classification, and finally comment on whether interpreted languages are perpetually slower than compiled ones and why.",I don't know the difference between compiled and interpreted languages.,0
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.","A process is an independent program in execution with its own memory space, while a thread is a lightweight unit of execution that exists within a process and shares its memory. Context switching is the mechanism by which the operating system saves the state of a running process or thread and restores the state of another so that multiple tasks can share the CPU efficiently. It is necessary to enable multitasking and responsive systems. Processes do not share memory by default, which makes them safer but heavier, whereas threads share the same memory space, making communication faster but requiring careful synchronization. Multithreading can significantly improve performance in applications like web servers, where multiple client requests can be handled concurrently.",94
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.","A process is a running program with its own resources, while a thread is a smaller execution unit inside a process that shares memory with other threads. Context switching allows the CPU to switch between processes or threads so that multiple tasks appear to run at the same time. Processes have separate memory spaces, but threads share memory, which makes threads faster to communicate. Multithreading improves performance in applications such as file download managers that perform multiple downloads simultaneously.",87
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.","Processes and threads are both execution units, but processes are heavier and have separate memory, while threads share memory within a process. Context switching helps the operating system run multiple tasks by switching between them. Threads share memory, so they are faster than processes. Multithreading is useful in applications like video streaming or games.",76
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.","A process is a program in execution, and a thread runs inside a process. Context switching is switching between tasks. Processes have separate memory, and threads share memory. Multithreading helps applications run faster.",66
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.",Processes and threads are used to run programs. Threads are smaller than processes. Context switching allows switching between them. Threads share memory. Multithreading can improve performance.,58
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.",A process runs a program. A thread is part of a process. Context switching changes tasks. Threads share memory.,44
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.",Processes and threads are different. Threads are smaller.,36
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.",A process and thread are parts of a program.,23
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.",Process and thread are operating system terms.,14
Q5,"An operating system process is a program in execution, and it differs from a thread in that a thread is the smallest sequence of programmed instructions that can be managed independently by a scheduler. Describe context switching and its necessity. Elaborate on the differences in memory sharing between processes and threads and provide an instance where the use of multithreading can dramatically enhance the performance of an application.",I don't know about processes and threads.,0
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.","Database normalization is the process of structuring a database to reduce data redundancy and improve data integrity. The first normal form ensures that all table attributes contain atomic values and there are no repeating groups. The second normal form builds on this by removing partial dependencies, meaning non-key attributes depend on the entire primary key. The third normal form removes transitive dependencies so that non-key attributes depend only on the primary key. While normalization improves consistency, excessive normalization can lead to complex queries and performance overhead due to multiple joins. In read-heavy systems such as analytics platforms or reporting dashboards, denormalization is often preferred to improve query performance.",97
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.","Normalization organizes database tables to avoid duplication and maintain consistency. First normal form ensures single-valued attributes, second normal form removes partial dependency on a composite key, and third normal form removes dependency between non-key attributes. Over-normalization can slow down queries and make database design complex. Denormalization can be useful in systems where fast reads are more important than strict normalization, such as e-commerce product catalogs.",88
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.","Database normalization reduces redundancy in tables. First normal form removes repeating values, second normal form removes partial dependency, and third normal form removes transitive dependency. Too much normalization can cause performance issues due to many joins. Denormalization is used when faster access is needed.",76
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.","Normalization is used to organize data properly in databases. First, second, and third normal forms remove different types of dependencies. Over-normalization can make queries slower. Denormalization can improve performance in some cases.",67
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.","Database normalization helps reduce duplicate data. There are different normal forms like first, second, and third. Too much normalization can be bad for performance. Sometimes denormalization is better.",56
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.",Normalization is a way to design databases. It reduces duplication. There are multiple normal forms. Denormalization can help performance.,44
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.",Normalization is used in databases to organize data. There are normal forms.,35
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.",Normalization means structuring data in databases.,24
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.",Normalization is related to databases.,13
Q6,"Database normalization is a technique of organizing data in a database to minimize redundancy and dependency. Explain simply the first, second, and third normal forms. Also, discuss the disadvantages of excessive normalization and explain situations where denormalization may be a better design choice.",I don't know database normalization.,0
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.","Machine Learning is a field of Artificial Intelligence where systems learn patterns from data and improve performance without being explicitly programmed with fixed rules. Unlike rule-based programming, where logic is manually defined by developers, Machine Learning models learn rules automatically from examples. In supervised learning, models are trained using labeled data, such as email spam detection where emails are marked as spam or not spam. Unsupervised learning works with unlabeled data and is used in applications like customer segmentation. Reinforcement learning involves an agent learning through rewards and penalties, such as training an AI to play games. Key limitations of Machine Learning include dependence on large amounts of quality data, risk of bias, lack of interpretability, and difficulty in generalizing to unseen scenarios.",96
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.","Machine Learning allows computers to learn from data instead of following manually written rules. Supervised learning uses labeled data like predicting house prices, unsupervised learning finds patterns such as clustering users, and reinforcement learning learns through feedback, such as robots learning to walk. Challenges of Machine Learning include data bias, high computational cost, and limited explainability.",88
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.","Machine Learning is different from rule-based systems because it learns from data. Supervised learning uses labeled data, unsupervised learning uses unlabeled data, and reinforcement learning learns by trial and error. Examples include spam filtering, grouping similar items, and game-playing agents. Machine Learning systems require a lot of data and computing power.",74
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.","Machine Learning learns from data, while rule-based programming follows fixed rules. Supervised, unsupervised, and reinforcement learning are different types. Examples include prediction, clustering, and training agents. Machine Learning has limitations like needing data",65
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.",Machine Learning is about learning from data. There are different types such as supervised and unsupervised learning. It is used in many applications. It also has some limitations.,57
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.",Machine Learning uses data to learn patterns. It is different from traditional programming. There are types of Machine Learning.,46
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.",Machine Learning is part of AI. It uses data.,34
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.",Machine Learning is related to Artificial Intelligence.,25
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.",Machine Learning is about machines learning.,13
Q7,"Machine Learning is a subfield of Artificial Intelligence that learns from data. Explain how Machine Learning differs from traditional rule-based programming. Differentiate between supervised, unsupervised, and reinforcement learning. Give one real-world example for each, and finally discuss the key limitations or challenges of Machine Learning systems.",I don't know Machine Learning.,0
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.","Artificial Intelligence (AI) is a field of computer science focused on creating systems that can perform tasks requiring human-like intelligence, such as reasoning, problem-solving, and decision-making. Machine Learning is a subset of AI that enables systems to learn patterns from data rather than relying on explicitly programmed rules. Not all AI systems use Machine Learning; traditional AI systems often rely on rule-based logic and predefined conditions. Deep learning is a further subset of Machine Learning that uses neural networks with multiple layers to model complex patterns. An example of a non-ML AI system is a rule-based expert system used in early medical diagnosis software, where decisions are made using predefined if-then rules created by domain experts.",95
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.","Artificial Intelligence refers to machines that can simulate intelligent behavior. Machine Learning is a part of AI that allows systems to learn from data. Not every AI system depends on Machine Learning, as some systems work purely on rules. Deep learning is a type of Machine Learning that uses neural networks. A chess program based on fixed rules and heuristics is an example of AI without Machine Learning.",87
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.","AI is the concept of making machines intelligent, while Machine Learning allows machines to learn from data. Machine Learning is a subset of AI, and deep learning is a subset of Machine Learning. Some AI systems do not use Machine Learning and instead rely on hard-coded rules, such as basic game-playing programs.",75
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.",Artificial Intelligence is about making computers smart. Machine Learning is part of AI and uses data to learn. Deep learning comes under Machine Learning. Some AI systems work without Machine Learning using rules.,66
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.",AI means computers doing intelligent tasks. Machine Learning helps computers learn. Deep learning is related to Machine Learning. Some AI systems work using rules instead of learning.,54
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.",Artificial Intelligence is used to make machines intelligent. Machine Learning is connected to AI. Deep learning is part of Machine Learning. Some AI systems do not learn.,43
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.",AI and Machine Learning are related fields. AI is bigger than Machine Learning. Deep learning is also related.,36
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.",AI is about machines acting smart. Machine Learning is part of it.,22
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.",Artificial Intelligence is when computers try to think like humans. Machine Learning is related to it.,17
Q8,"Define Artificial Intelligence and explain its relationship with Machine Learning. Clarify if all AI systems use Machine Learning and where deep learning is located within this relationship. Besides that, give an example of an AI system that does not rely on Machine Learning and explain how it works.",Artificial Intelligence is used to make machines intelligent.,4
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.","When a user types a URL into a browser and presses Enter, the browser first checks if the domain name is already cached. If not, it sends a DNS request to resolve the domain name into an IP address. Once the IP address is obtained, the browser establishes a connection with the server using the TCP/IP protocol through a three-way handshake. After the connection is established, an HTTPS request is sent, during which TLS encryption is negotiated to secure the communication. The server then processes the request and sends back an encrypted response, which the browser decrypts and renders as a web page. HTTPS ensures data confidentiality and integrity throughout this exchange.",97
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.","After entering a URL, the browser uses DNS to find the server's IP address. It then creates a connection with the server using TCP/IP. If the site uses HTTPS, encryption is applied to secure the data being transferred. Finally, the server sends the webpage back to the browser, which displays it to the user.",88
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.","When a URL is entered, the browser contacts DNS to get the IP address of the website. Then it connects to the server using TCP/IP. HTTPS is used to encrypt the data so that communication is secure. The webpage is then loaded in the browser.",74
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.",Typing a URL causes the browser to find the website's address using DNS. The browser then connects to the server using network protocols. HTTPS provides security during data transfer.,67
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.","When a URL is typed, the browser contacts DNS and connects to the server. HTTPS helps protect the data sent between the browser and server.",56
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.",The browser uses DNS to find the website and then connects to it. HTTPS makes the connection secure.,44
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.",The browser opens the website by connecting to the server. DNS is involved.,33
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.","When a URL is typed, the browser tries to open the website. DNS helps find it, and HTTPS is related to security.",24
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.",The browser loads the website from the internet using the URL.,13
Q9,"What happens when a user types a URL into a web browser and presses Enter? Describe the role of DNS in this process, explain how TCP/IP is used to establish communication between the client and server, and discuss where and how HTTPS encryption is applied during this interaction.",The URL helps the browser find a website and show it.,3
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.","The Software Development Lifecycle is a structured approach used to plan, build, test, deploy, and maintain software systems. The main phases typically include requirement analysis, system design, implementation, testing, deployment, and maintenance. The waterfall model follows these phases sequentially, where each phase must be completed before moving to the next, making it suitable for projects with well-defined and stable requirements. Agile development, on the other hand, is iterative and incremental, focusing on continuous feedback, frequent releases, and close collaboration with stakeholders. Agile is preferred when requirements are likely to change, such as in product-based or startup environments, while waterfall is often chosen for regulated or contract-based projects where changes are costly.",98
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.","SDLC defines the steps involved in building software, starting from gathering requirements to maintaining the final product. Waterfall is a linear model where progress flows in one direction, while agile breaks development into small iterations with regular feedback. Waterfall works well when requirements are fixed, whereas agile is better suited for dynamic projects that need flexibility and faster delivery.",87
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.","The Software Development Lifecycle consists of phases like planning, design, development, testing, and deployment. The waterfall model completes these phases one by one, while agile allows repeating phases in short cycles. Agile is useful when changes are expected, and waterfall is better when requirements are clear from the beginning.",76
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.","SDLC is a process for developing software. It includes stages such as design, development, and testing. Waterfall is a step-by-step model, and agile is iterative. Agile allows changes, while waterfall does not.",64
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.","SDLC is used to develop software properly. It has multiple phases. Waterfall and agile are two models. Agile is flexible, and waterfall is structured.",55
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.",SDLC is a method used in software development. Waterfall and agile are development models. Agile is faster.,43
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.",SDLC is related to software development. Waterfall and agile are methods.,36
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.",SDLC is about developing software in steps. Agile and waterfall are types of development models.,23
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.",SDLC is a process for making software.,12
Q10,"Software Development Lifecycle (SDLC) is a systematic process used by development teams to produce high-quality software in a cost-effective and timely manner. Explain the main phases of the SDLC, compare the traditional waterfall and agile development models, and discuss reasons for choosing one model over the other.",SDLC is used in software projects.,2
